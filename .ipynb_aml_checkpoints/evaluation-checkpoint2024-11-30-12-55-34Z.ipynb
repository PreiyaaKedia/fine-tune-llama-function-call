{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from datetime import datetime\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import re\n",
        "import yaml\n",
        "import time\n",
        "import json"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1735562006869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = load_dataset(\"glaiveai/glaive-function-calling-v2\", split=\"train\")\n",
        "val_dataset = dataset.select(range(100))\n",
        "\n",
        "print(val_dataset[1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'system': 'SYSTEM: You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"get_news_headlines\",\\n    \"description\": \"Get the latest news headlines\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"country\": {\\n                \"type\": \"string\",\\n                \"description\": \"The country for which to fetch news\"\\n            }\\n        },\\n        \"required\": [\\n            \"country\"\\n        ]\\n    }\\n}\\n', 'chat': 'USER: Can you tell me the latest news headlines for the United States?\\n\\n\\nASSISTANT: <functioncall> {\"name\": \"get_news_headlines\", \"arguments\": \\'{\"country\": \"United States\"}\\'} <|endoftext|>\\n\\n\\nFUNCTION RESPONSE: {\"headlines\": [\"Biden announces new vaccine mandates\", \"Hurricane Ida devastates Louisiana\", \"Apple unveils new iPhone\", \"NASA\\'s Perseverance rover collects first Mars rock sample\"]}\\n\\n\\nASSISTANT: Here are the latest news headlines for the United States:\\n1. Biden announces new vaccine mandates\\n2. Hurricane Ida devastates Louisiana\\n3. Apple unveils new iPhone\\n4. NASA\\'s Perseverance rover collects first Mars rock sample <|endoftext|>\\n\\n\\nUSER: That\\'s interesting. What about the news in France?\\n\\n\\nASSISTANT: <functioncall> {\"name\": \"get_news_headlines\", \"arguments\": \\'{\"country\": \"France\"}\\'} <|endoftext|>\\n\\n\\nFUNCTION RESPONSE: {\"headlines\": [\"France recalls ambassadors to US and Australia\", \"French election: Macron\\'s party braces for tough fight\", \"Louvre Museum to undergo major overhaul\", \"France to offer free birth control to all women under 25\"]}\\n\\n\\nASSISTANT: Here are the latest news headlines for France:\\n1. France recalls ambassadors to US and Australia\\n2. French election: Macron\\'s party braces for tough fight\\n3. Louvre Museum to undergo major overhaul\\n4. France to offer free birth control to all women under 25 <|endoftext|>\\n\\n\\n'}\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735562053753
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_conversation(input_string):  \n",
        "    \n",
        "    ROLE_MAPPING = {\"USER\" : \"user\", \"ASSISTANT\" : \"assistant\", \"SYSTEM\" : \"system\", \"FUNCTION RESPONSE\" : \"tool\"}\n",
        "\n",
        "    # Regular expression to split the conversation based on SYSTEM, USER, and ASSISTANT  \n",
        "    pattern = r\"(SYSTEM|USER|ASSISTANT|FUNCTION RESPONSE):\"  \n",
        "      \n",
        "    # Split the input string and keep the delimiters  \n",
        "    parts = re.split(pattern, input_string)  \n",
        "      \n",
        "    # Initialize the list to store conversation entries  \n",
        "    conversation = []  \n",
        "      \n",
        "    # Iterate over the parts, skipping the first empty string  \n",
        "    for i in range(1, len(parts), 2):  \n",
        "        role = parts[i].strip()  \n",
        "        content = parts[i + 1].strip()  \n",
        "        content = content.replace(\"<|endoftext|>\", \"\").strip()\n",
        "\n",
        "        if content.startswith('<functioncall>'):  # build structured data for function call\n",
        "                # try to turn function call from raw text to structured data\n",
        "                content = content.replace('<functioncall>', '').strip()\n",
        "                # replace single quotes with double quotes for valid JSON\n",
        "                clean_content = content.replace(\"'{\", '{').replace(\"'}\", '}')\n",
        "                data_json = json.loads(clean_content)\n",
        "                # Make it compatible with openAI prompt format\n",
        "                func_call = {'recipient_name': f\"functions.{data_json['name']}\", 'parameters': data_json['arguments']}\n",
        "                content = {'tool_uses': [func_call]}\n",
        "          \n",
        "        # Append a dictionary with the role and content to the conversation list  \n",
        "        conversation.append({\"role\": ROLE_MAPPING[role], \"content\": content})  \n",
        "      \n",
        "    return conversation  \n",
        "\n",
        "def apply_chat_template(examples):\n",
        "        conversations = []\n",
        "        for system, chat in zip(examples[\"system\"], examples[\"chat\"]):\n",
        "            try:\n",
        "                system_message = parse_conversation(system)\n",
        "                chat_message = parse_conversation(chat)\n",
        "                message = system_message + chat_message\n",
        "                conversations.append(message)\n",
        "            except Exception as e:\n",
        "                print(e) \n",
        "\n",
        "        text = [tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=False) for message in conversations]\n",
        "        return {\"text\": text}\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735562010614
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_val_dataset = []\n",
        "for i in range(len(val_dataset)):\n",
        "    system_message = parse_conversation(val_dataset[i][\"system\"])\n",
        "    chat_message = parse_conversation(val_dataset[i][\"chat\"])\n",
        "\n",
        "    message = system_message + chat_message\n",
        "    processed_val_dataset.append(message)  "
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735563113925
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### First level response\n",
        "def get_qna_pairs(message):\n",
        "    prompt = []\n",
        "    answer = []\n",
        "    for item in message:\n",
        "        if item['role'] == 'assistant':\n",
        "            response = item['content']\n",
        "            answer.append(response)\n",
        "            break\n",
        "        else:\n",
        "            prompt.append(item)\n",
        "    \n",
        "    return prompt, answer\n"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735562981330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = []\n",
        "responses = []\n",
        "for example in processed_val_dataset:\n",
        "    prompt, answer = get_qna_pairs(example)\n",
        "    prompts.append(prompt)\n",
        "    responses.append(answer)\n",
        "\n",
        "print(prompts[0])\n",
        "print(responses[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[{'role': 'system', 'content': 'You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"get_exchange_rate\",\\n    \"description\": \"Get the exchange rate between two currencies\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"base_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert from\"\\n            },\\n            \"target_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert to\"\\n            }\\n        },\\n        \"required\": [\\n            \"base_currency\",\\n            \"target_currency\"\\n        ]\\n    }\\n}'}, {'role': 'user', 'content': 'Can you book a flight for me from New York to London?'}]\n[\"I'm sorry, but I don't have the capability to book flights. My current function allows me to get the exchange rate between two currencies. If you need help with that, feel free to ask!\"]\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735563203175
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}