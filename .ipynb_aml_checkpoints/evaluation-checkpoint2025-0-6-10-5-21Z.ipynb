{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!az login --tenant fdpo.onmicrosoft.com"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import the pip dependencies\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "import sys\n",
        "# !{sys.executable} -m pip install azure-ai-evaluation\n",
        "!{sys.executable} -m pip install azure-ai-evaluation[remote]"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735802020531
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"./slm_perf_output.csv\")\n",
        "\n",
        "sample = dataset.iloc[0]\n",
        "print(sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prompt      [{'role': 'system', 'content': 'You are a help...\nActual      {'tool_uses': [{'recipient_name': 'functions.s...\nExpected    {'tool_uses': [{'recipient_name': 'functions.s...\nMatch                                                      No\nName: 0, dtype: object\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735797240241
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "from azure.ai.evaluation import BleuScoreEvaluator, GleuScoreEvaluator, MeteorScoreEvaluator, RougeScoreEvaluator, RougeType\n",
        "\n",
        "bleu = BleuScoreEvaluator()\n",
        "glue = GleuScoreEvaluator()\n",
        "meteor = MeteorScoreEvaluator(alpha = 0.9, beta = 3.0, gamma = 0.5)\n",
        "rouge = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_L)\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735823797379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./llama-fc_config.yaml') as f:\n",
        "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
        "    \n",
        "AZURE_SUBSCRIPTION_ID = d['config']['AZURE_SUBSCRIPTION_ID']\n",
        "AZURE_RESOURCE_GROUP = d['config']['AZURE_RESOURCE_GROUP']\n",
        "AZURE_WORKSPACE = d['config']['AZURE_WORKSPACE']\n",
        "AZURE_DATA_NAME = d['config']['AZURE_SFT_DATA_NAME']    \n",
        "DATA_DIR = d['config']['SFT_DATA_DIR']\n",
        "CLOUD_DIR = d['config']['CLOUD_DIR']\n",
        "HF_MODEL_NAME_OR_PATH = d['config']['HF_MODEL_NAME_OR_PATH']\n"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735802487811
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./slm_perf_output.csv\")\n",
        "df.rename(columns = {\"Actual\" : \"ground_truth\", \"Expected\" : \"response\"}, inplace = True)\n",
        "df.to_json(\"./eval_baseline_data.jsonl\", orient = \"records\", lines = True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735797266180
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <mySubscriptionID>: Subscription ID of the Azure AI Studio hub's linked storage account (available in Azure AI hub resource view in Azure Portal).\n",
        "# <myResourceGroupName>: Resource group of the Azure AI Studio hub's linked storage account.\n",
        "# <user-id>: User object ID for role assignment (retrieve with \"az ad user show\" command).\n",
        "\n",
        "! az role assignment create --role \"Storage Blob Data Contributor\" --scope /subscriptions/8cebb108-a4d5-402b-a0c4-f7556126277f/resourceGroups/openairesourcegroup_priya --assignee-principal-type User --assignee-object-id \"8b6b15cc-9937-4208-8173-97ea0b9e1a13\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import evaluate\n",
        "\n",
        "result = evaluate(\n",
        "    data=\"./eval_baseline_data.jsonl\",\n",
        "    evaluators={\n",
        "        \"bleu\": bleu,\n",
        "        \"gleu\": glue,\n",
        "        \"meteor\": meteor,\n",
        "        \"rouge\" : rouge\n",
        "    },\n",
        "    # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\n",
        "    azure_ai_project={\n",
        "        \"subscription_id\": \"8cebb108-a4d5-402b-a0c4-f7556126277f\",\n",
        "        \"resource_group_name\": \"openAIResourceGroup_priya\",\n",
        "        \"project_name\": \"priyakedia-1214\",\n",
        "    },\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting prompt flow service...\nStarting prompt flow service...\nStarting prompt flow service...\nStarting prompt flow service...\nStart prompt flow service on 127.0.0.1:23333, version: 1.16.2.\nStart prompt flow service on 127.0.0.1:23333, version: 1.16.2.\nStart prompt flow service on 127.0.0.1:23333, version: 1.16.2.\nStart prompt flow service on 127.0.0.1:23333, version: 1.16.2.\nYou can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n\nYou can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_5zceet7l_20250102_132223_436445\nYou can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n\nYou can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_x9uaisp7_20250102_132223_429915\nYou can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n\nYou can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_w6m3kypy_20250102_132223_437438\nYou can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n\nYou can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_7hhhw9p6_20250102_132223_434701\n2025-01-02 13:22:30 +0000    7014 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-01-02 13:22:37 +0000    7014 execution.bulk     INFO     Finished 376 / 376 lines.\n2025-01-02 13:22:37 +0000    7014 execution.bulk     INFO     Average execution time for completed lines: 0.02 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_5zceet7l_20250102_132223_436445\"\nRun status: \"Completed\"\nStart time: \"2025-01-02 13:22:23.432273+00:00\"\nDuration: \"0:00:13.865763\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_5zceet7l_20250102_132223_436445\"\n\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Finished 376 / 376 lines.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Average execution time for completed lines: 0.04 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Finished 376 / 376 lines.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Average execution time for completed lines: 0.04 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2025-01-02 13:22:31 +0000    7014 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Finished 376 / 376 lines.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Average execution time for completed lines: 0.04 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_7hhhw9p6_20250102_132223_434701\"\nRun status: \"Completed\"\nStart time: \"2025-01-02 13:22:23.428741+00:00\"\nDuration: \"0:00:21.222986\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_7hhhw9p6_20250102_132223_434701\"\n\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Finished 376 / 376 lines.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Average execution time for completed lines: 0.04 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2025-01-02 13:22:30 +0000    7014 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Finished 376 / 376 lines.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Average execution time for completed lines: 0.04 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_x9uaisp7_20250102_132223_429915\"\nRun status: \"Completed\"\nStart time: \"2025-01-02 13:22:23.428289+00:00\"\nDuration: \"0:00:21.398664\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_x9uaisp7_20250102_132223_429915\"\n\n2025-01-02 13:22:30 +0000    7014 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Finished 376 / 376 lines.\n2025-01-02 13:22:44 +0000    7014 execution.bulk     INFO     Average execution time for completed lines: 0.04 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_w6m3kypy_20250102_132223_437438\"\nRun status: \"Completed\"\nStart time: \"2025-01-02 13:22:23.435387+00:00\"\nDuration: \"0:00:21.548841\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_w6m3kypy_20250102_132223_437438\"\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[2025-01-02 13:22:30 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-01-02 13:22:30 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_5zceet7l_20250102_132223_436445, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_rouge_rouge_asyncrougescoreevaluator_5zceet7l_20250102_132223_436445/logs.txt\n[2025-01-02 13:22:30 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-01-02 13:22:30 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_x9uaisp7_20250102_132223_429915, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_bleu_bleu_asyncbleuscoreevaluator_x9uaisp7_20250102_132223_429915/logs.txt\n[2025-01-02 13:22:30 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-01-02 13:22:30 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_w6m3kypy_20250102_132223_437438, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_meteor_meteor_asyncmeteorscoreevaluator_w6m3kypy_20250102_132223_437438/logs.txt\n[2025-01-02 13:22:30 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-01-02 13:22:30 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_7hhhw9p6_20250102_132223_434701, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_gleu_gleu_asyncgleuscoreevaluator_7hhhw9p6_20250102_132223_434701/logs.txt\n"
        },
        {
          "output_type": "error",
          "ename": "EvaluationException",
          "evalue": "(InternalError) The workspace datastore secrets request failed with HTTP 400",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEvaluationException\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./eval_baseline_data.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbleu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbleu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgleu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mglue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeteor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeteor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrouge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouge\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubscription_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m8cebb108-a4d5-402b-a0c4-f7556126277f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresource_group_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenAIResourceGroup_priya\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproject_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpriyakedia-1214\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:651\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EvaluationException):\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[1;32m    645\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    646\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mEVALUATE,\n\u001b[1;32m    647\u001b[0m         category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mFAILED_EXECUTION,\n\u001b[1;32m    648\u001b[0m         blame\u001b[38;5;241m=\u001b[39mErrorBlame\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    649\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:610\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates target or data with built-in or custom evaluators. If both target and data are provided,\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m    data will be run through target function and then results will be evaluated.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m        :caption: Run an evaluation on local data with Coherence and Relevance evaluators.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# Handle multiprocess bootstrap error\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     bootstrap_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn attempt has been made to start a new process before the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent process has finished its bootstrapping phase.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:815\u001b[0m, in \u001b[0;36m_evaluate\u001b[0;34m(evaluators, evaluation_name, target, data, evaluator_config, azure_ai_project, output_path, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m studio_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_destination:\n\u001b[0;32m--> 815\u001b[0m     studio_url \u001b[38;5;241m=\u001b[39m \u001b[43m_log_metrics_and_instance_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_destination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m result_df_dict \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    820\u001b[0m result: EvaluationResult \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m: result_df_dict, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudio_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: studio_url}  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/evaluation/_evaluate/_utils.py:183\u001b[0m, in \u001b[0;36m_log_metrics_and_instance_results\u001b[0;34m(metrics, instance_results, trace_destination, run, evaluation_name, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tmp_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mDefaultOpenEncoding\u001b[38;5;241m.\u001b[39mWRITE) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    181\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(instance_results\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 183\u001b[0m \u001b[43mev_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Using mlflow to create a dummy run since once created via PF show traces of dummy run in UI.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Those traces can be confusing.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# adding these properties to avoid showing traces if a dummy run is created.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# We are doing that only for the pure evaluation runs.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/evaluation/_evaluate/_eval_run.py:424\u001b[0m, in \u001b[0;36mEvalRun.log_artifact\u001b[0;34m(self, artifact_folder, artifact_name)\u001b[0m\n\u001b[1;32m    421\u001b[0m         local_paths\u001b[38;5;241m.\u001b[39mappend(local_file_path)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# We will write the artifacts to the workspaceblobstore\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m datastore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_management_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace_get_default_datastore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m account_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatastore\u001b[38;5;241m.\u001b[39maccount_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.blob.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatastore\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m svc_client \u001b[38;5;241m=\u001b[39m BlobServiceClient(account_url\u001b[38;5;241m=\u001b[39maccount_url, credential\u001b[38;5;241m=\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mcredential)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/evaluation/_azure/_clients.py:112\u001b[0m, in \u001b[0;36mLiteMLClient.workspace_get_default_datastore\u001b[0;34m(self, workspace_name, include_credentials)\u001b[0m\n\u001b[1;32m    101\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_path(\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;241m*\u001b[39mPATH_ML_WORKSPACES, workspace_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatastores\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkspaceblobstore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistSecrets\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m secrets_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    105\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    111\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_throw_on_http_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecrets_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworkspace datastore secrets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m secrets_json \u001b[38;5;241m=\u001b[39m secrets_response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    115\u001b[0m secrets_type \u001b[38;5;241m=\u001b[39m secrets_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecretsType\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/evaluation/_azure/_clients.py:174\u001b[0m, in \u001b[0;36mLiteMLClient._throw_on_http_error\u001b[0;34m(response, description, valid_status)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (JSONDecodeError, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[1;32m    175\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m request failed with HTTP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m     target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mEVALUATE,\n\u001b[1;32m    177\u001b[0m     category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mFAILED_EXECUTION,\n\u001b[1;32m    178\u001b[0m     blame\u001b[38;5;241m=\u001b[39mErrorBlame\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    179\u001b[0m     internal_message\u001b[38;5;241m=\u001b[39madditional_info,\n\u001b[1;32m    180\u001b[0m )\n",
            "\u001b[0;31mEvaluationException\u001b[0m: (InternalError) The workspace datastore secrets request failed with HTTP 400"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735824167931
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(result[\"rows\"])\n",
        "\n",
        "# df\n",
        "\n",
        "# sample_df = df.loc[df[\"inputs.ground_truth\"].str.startswith(\"{'tool_uses'}\")]\n",
        "# sample_df = df.loc[df[\"inputs.ground_truth\"].str.startswith(\"{'tool_uses'}\")]  \n",
        "\n",
        "# sample_df\n",
        "\n",
        "index = 19\n",
        "\n",
        "# df.iloc[index][\"inputs.ground_truth\"]\n",
        "df.iloc[index][\"inputs.response\"]\n",
        "\n",
        "# print(\"\\n\", df.iloc[0][\"inputs.response\"])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 57,
          "data": {
            "text/plain": "\"{'tool_uses': [{'recipient_name': 'functions.calculate_age', 'parameters': {'birthdate': '1990-05-15'}}]}\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735810348331
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import GleuScoreEvaluator\n",
        "\n",
        "gleu = GleuScoreEvaluator()"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735590790408
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}