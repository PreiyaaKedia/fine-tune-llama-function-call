{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "import time\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient, Input\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml.entities import Data, Environment, BuildContext\n",
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml import Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.core.exceptions import ResourceNotFoundError, ResourceExistsError\n",
        "from azureml.core import Workspace, Run\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1735567019657
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./llama-fc_config.yaml') as f:\n",
        "    d = yaml.load(f, Loader=yaml.FullLoader)\n",
        "    \n",
        "AZURE_SUBSCRIPTION_ID = d['config']['AZURE_SUBSCRIPTION_ID']\n",
        "AZURE_RESOURCE_GROUP = d['config']['AZURE_RESOURCE_GROUP']\n",
        "AZURE_WORKSPACE = d['config']['AZURE_WORKSPACE']\n",
        "AZURE_DATA_NAME = d['config']['AZURE_SFT_DATA_NAME']    \n",
        "DATA_DIR = d['config']['SFT_DATA_DIR']\n",
        "CLOUD_DIR = d['config']['CLOUD_DIR']\n",
        "HF_MODEL_NAME_OR_PATH = d['config']['HF_MODEL_NAME_OR_PATH']\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735567044736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credential = DefaultAzureCredential()\n",
        "ml_client = None\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    ml_client = MLClient(credential, AZURE_SUBSCRIPTION_ID, AZURE_RESOURCE_GROUP, AZURE_WORKSPACE)\n",
        "\n",
        "def get_or_create_model_asset(ml_client, model_name, experiment_name = None, job_name = None, model_dir=\"outputs\", model_type=\"custom_model\", update=False):\n",
        "    \n",
        "    try:\n",
        "        latest_model_version = max([int(m.version) for m in ml_client.models.list(name=model_name)])\n",
        "        if update:\n",
        "            raise ResourceExistsError('Found Model asset, but will update the Model.')\n",
        "        else:\n",
        "            model_asset = ml_client.models.get(name=model_name, version=latest_model_version)\n",
        "            print(f\"Found Model asset: {model_name}. Will not create again\")\n",
        "    except (ResourceNotFoundError, ResourceExistsError) as e:\n",
        "        print(f\"Exception: {e}\") \n",
        "        ws = Workspace.from_config()  \n",
        "  \n",
        "        # Get the run by its ID   \n",
        "        run = Run(ws.experiments[experiment_name], job_name)  \n",
        "        # Register the model  \n",
        "        model_asset = run.register_model(  \n",
        "            model_name=model_name,  # this is the name the model will be registered under  \n",
        "            model_path=model_dir  # this is the path to the model file in the run's outputs  \n",
        "        )         \n",
        "        print(f\"Created Model asset: {model_name}\")\n",
        "\n",
        "    return model_asset\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735567055486
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_or_create_model_asset(ml_client, d['serve']['azure_model_name'], update = False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found Model asset: llama-fc-ft. Will not create again\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735567063430
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "model_kwargs = dict(\n",
        "        trust_remote_code=True,    \n",
        "        device_map={\"\":0},\n",
        "        torch_dtype=\"auto\" \n",
        "    )\n",
        "    \n",
        "model = AutoModelForCausalLM.from_pretrained(\"./model/outputs\", **model_kwargs)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f61b9723ddc54c2ca69b0c5e052804ce"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735567669718
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"./model/outputs\")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735567290454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"glaiveai/glaive-function-calling-v2\", split=\"train\")\n",
        "val_dataset = dataset.select(range(2000, 2200))\n",
        "\n",
        "print(val_dataset[-1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'system': 'SYSTEM: You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"create_event\",\\n    \"description\": \"Create a new event in the calendar\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"title\": {\\n                \"type\": \"string\",\\n                \"description\": \"The title of the event\"\\n            },\\n            \"start_time\": {\\n                \"type\": \"string\",\\n                \"description\": \"The start time of the event\"\\n            },\\n            \"end_time\": {\\n                \"type\": \"string\",\\n                \"description\": \"The end time of the event\"\\n            }\\n        },\\n        \"required\": [\\n            \"title\",\\n            \"start_time\",\\n            \"end_time\"\\n        ]\\n    }\\n}\\n\\n{\\n    \"name\": \"generate_random_number\",\\n    \"description\": \"Generate a random number within a given range\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"min\": {\\n                \"type\": \"integer\",\\n                \"description\": \"The minimum value of the range\"\\n            },\\n            \"max\": {\\n                \"type\": \"integer\",\\n                \"description\": \"The maximum value of the range\"\\n            }\\n        },\\n        \"required\": [\\n            \"min\",\\n            \"max\"\\n        ]\\n    }\\n}\\n\\n', 'chat': 'USER: I need to schedule a meeting for tomorrow.\\n\\n\\nASSISTANT: Sure, I can help with that. Could you please provide me with the title, start time, and end time for the meeting? <|endoftext|>\\n\\n\\nUSER: The title is \"Project Discussion\", it should start at 10:00 AM and end at 11:00 AM.\\n\\n\\nASSISTANT: <functioncall> {\"name\": \"create_event\", \"arguments\": \\'{\"title\": \"Project Discussion\", \"start_time\": \"10:00 AM\", \"end_time\": \"11:00 AM\"}\\'} <|endoftext|>\\n\\n\\nFUNCTION RESPONSE: {\"status\": \"success\", \"message\": \"Event \\'Project Discussion\\' has been successfully created for tomorrow from 10:00 AM to 11:00 AM.\"}\\n\\n\\nASSISTANT: The meeting titled \"Project Discussion\" has been successfully scheduled for tomorrow from 10:00 AM to 11:00 AM. <|endoftext|>\\n\\n\\n'}\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735572858195
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def parse_conversation(input_string):  \n",
        "    \n",
        "    ROLE_MAPPING = {\"USER\" : \"user\", \"ASSISTANT\" : \"assistant\", \"SYSTEM\" : \"system\", \"FUNCTION RESPONSE\" : \"tool\"}\n",
        "\n",
        "    # Regular expression to split the conversation based on SYSTEM, USER, and ASSISTANT  \n",
        "    pattern = r\"(SYSTEM|USER|ASSISTANT|FUNCTION RESPONSE):\"  \n",
        "      \n",
        "    # Split the input string and keep the delimiters  \n",
        "    parts = re.split(pattern, input_string)  \n",
        "      \n",
        "    # Initialize the list to store conversation entries  \n",
        "    conversation = []  \n",
        "      \n",
        "    # Iterate over the parts, skipping the first empty string  \n",
        "    for i in range(1, len(parts), 2):  \n",
        "        role = parts[i].strip()  \n",
        "        content = parts[i + 1].strip()  \n",
        "        content = content.replace(\"<|endoftext|>\", \"\").strip()\n",
        "\n",
        "        if content.startswith('<functioncall>'):  # build structured data for function call\n",
        "                # try to turn function call from raw text to structured data\n",
        "                content = content.replace('<functioncall>', '').strip()\n",
        "                # replace single quotes with double quotes for valid JSON\n",
        "                clean_content = content.replace(\"'{\", '{').replace(\"'}\", '}')\n",
        "                data_json = json.loads(clean_content)\n",
        "                # Make it compatible with openAI prompt format\n",
        "                func_call = {'recipient_name': f\"functions.{data_json['name']}\", 'parameters': data_json['arguments']}\n",
        "                content = {'tool_uses': [func_call]}\n",
        "          \n",
        "        # Append a dictionary with the role and content to the conversation list  \n",
        "        conversation.append({\"role\": ROLE_MAPPING[role], \"content\": content})  \n",
        "      \n",
        "    return conversation  \n",
        "\n",
        "def apply_chat_template(examples):\n",
        "        conversations = []\n",
        "        for system, chat in zip(examples[\"system\"], examples[\"chat\"]):\n",
        "            try:\n",
        "                system_message = parse_conversation(system)\n",
        "                chat_message = parse_conversation(chat)\n",
        "                message = system_message + chat_message\n",
        "                conversations.append(message)\n",
        "            except Exception as e:\n",
        "                print(e) \n",
        "\n",
        "        text = [tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=False) for message in conversations]\n",
        "        return {\"text\": text}\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735567471795
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_val_dataset = []\n",
        "for i in range(len(val_dataset)):\n",
        "    system_message = parse_conversation(val_dataset[i][\"system\"])\n",
        "    chat_message = parse_conversation(val_dataset[i][\"chat\"])\n",
        "\n",
        "    message = system_message + chat_message\n",
        "    processed_val_dataset.append(message)  "
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735572904590
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### First level response\n",
        "def get_qna_pairs(message):\n",
        "    prompt = []\n",
        "    answer = []\n",
        "    for item in message:\n",
        "        if item['role'] == 'assistant':\n",
        "            response = item['content']\n",
        "            answer.append(response)\n",
        "            break\n",
        "        else:\n",
        "            prompt.append(item)\n",
        "    \n",
        "    return prompt, answer\n"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735573035176
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_level_prompts = []\n",
        "first_level_responses = []\n",
        "for example in processed_val_dataset:\n",
        "    prompt, answer = get_qna_pairs(example)\n",
        "    first_level_prompts.append(prompt)\n",
        "    first_level_responses.append(answer)\n",
        "\n",
        "# print(first_level_prompts[1])\n",
        "# print(first_level_responses[1])\n",
        "\n",
        "input_data = first_level_prompts[-1]\n",
        "print(input_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[{'role': 'system', 'content': 'You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"create_event\",\\n    \"description\": \"Create a new event in the calendar\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"title\": {\\n                \"type\": \"string\",\\n                \"description\": \"The title of the event\"\\n            },\\n            \"start_time\": {\\n                \"type\": \"string\",\\n                \"description\": \"The start time of the event\"\\n            },\\n            \"end_time\": {\\n                \"type\": \"string\",\\n                \"description\": \"The end time of the event\"\\n            }\\n        },\\n        \"required\": [\\n            \"title\",\\n            \"start_time\",\\n            \"end_time\"\\n        ]\\n    }\\n}\\n\\n{\\n    \"name\": \"generate_random_number\",\\n    \"description\": \"Generate a random number within a given range\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"min\": {\\n                \"type\": \"integer\",\\n                \"description\": \"The minimum value of the range\"\\n            },\\n            \"max\": {\\n                \"type\": \"integer\",\\n                \"description\": \"The maximum value of the range\"\\n            }\\n        },\\n        \"required\": [\\n            \"min\",\\n            \"max\"\\n        ]\\n    }\\n}'}, {'role': 'user', 'content': 'I need to schedule a meeting for tomorrow.'}]\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735573037059
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Second-level response\n",
        "def get_level2_qna_pairs(message):\n",
        "    prompt = []\n",
        "    answer = []\n",
        "    is_first_response = False\n",
        "    for item in message:\n",
        "        if item['role'] == 'assistant' and not is_first_response:\n",
        "            is_first_response = True\n",
        "            prompt.append(item)\n",
        "        elif item['role'] == 'assistant' and is_first_response:\n",
        "            response = item['content']\n",
        "            answer.append(response)\n",
        "            break\n",
        "        else:\n",
        "            prompt.append(item)\n",
        "    \n",
        "    if answer is not None:\n",
        "        return prompt, answer\n",
        "    else:\n",
        "        return None, None"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735573319648
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_level_prompts = []\n",
        "second_level_responses = []\n",
        "for example in processed_val_dataset:\n",
        "    prompt, answer = get_level2_qna_pairs(example)\n",
        "    if prompt is not None:\n",
        "        second_level_prompts.append(prompt)\n",
        "        second_level_responses.append(answer)\n",
        "\n",
        "input_data = second_level_prompts[-1]\n",
        "print(second_level_responses[-1])\n",
        "print(input_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[{'tool_uses': [{'recipient_name': 'functions.create_event', 'parameters': {'title': 'Project Discussion', 'start_time': '10:00 AM', 'end_time': '11:00 AM'}}]}]\n[{'role': 'system', 'content': 'You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"create_event\",\\n    \"description\": \"Create a new event in the calendar\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"title\": {\\n                \"type\": \"string\",\\n                \"description\": \"The title of the event\"\\n            },\\n            \"start_time\": {\\n                \"type\": \"string\",\\n                \"description\": \"The start time of the event\"\\n            },\\n            \"end_time\": {\\n                \"type\": \"string\",\\n                \"description\": \"The end time of the event\"\\n            }\\n        },\\n        \"required\": [\\n            \"title\",\\n            \"start_time\",\\n            \"end_time\"\\n        ]\\n    }\\n}\\n\\n{\\n    \"name\": \"generate_random_number\",\\n    \"description\": \"Generate a random number within a given range\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"min\": {\\n                \"type\": \"integer\",\\n                \"description\": \"The minimum value of the range\"\\n            },\\n            \"max\": {\\n                \"type\": \"integer\",\\n                \"description\": \"The maximum value of the range\"\\n            }\\n        },\\n        \"required\": [\\n            \"min\",\\n            \"max\"\\n        ]\\n    }\\n}'}, {'role': 'user', 'content': 'I need to schedule a meeting for tomorrow.'}, {'role': 'assistant', 'content': 'Sure, I can help with that. Could you please provide me with the title, start time, and end time for the meeting?'}, {'role': 'user', 'content': 'The title is \"Project Discussion\", it should start at 10:00 AM and end at 11:00 AM.'}]\n"
        }
      ],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735573377114
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chat_completion(input_data):\n",
        "    inputs = tokenizer.apply_chat_template(input_data, tokenize = True, add_generation_prompt = True, return_tensors = \"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(input_ids = inputs, max_new_tokens = 1024, do_sample = True, temperature = 0.1)\n",
        "    response = tokenizer.decode(outputs[0][inputs.shape[-1]:], skip_special_tokens = True)\n",
        "\n",
        "    return response\n",
        "    \n",
        "response = get_chat_completion(input_data)\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'tool_uses': [{'recipient_name': 'functions.create_event', 'parameters': {'title': 'Project Discussion','start_time': '10:00 AM', 'end_time': '11:00 AM'}}]}\n"
        }
      ],
      "execution_count": 93,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735574468842
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if response[1:12] == \"'tool_uses'\":\n",
        "#     predicted_response = ast.literal_eval(response)\n",
        "#     if isinstance(predicted_response, dict):\n",
        "#         predicted_functions = [func[\"recipient_name\"] for func in predicted_response[\"tool_uses\"]]\n",
        "#         predicted_function_args = [func[\"parameters\"] for func in predicted_response[\"tool_uses\"]]\n",
        "\n",
        "#         actual_response = second_level_responses[-1][0]\n",
        "#         actual_functions = [func[\"recipient_name\"] for func in actual_response[\"tool_uses\"]]\n",
        "#         actual_function_args = [func[\"parameters\"] for func in actual_response[\"tool_uses\"]]\n",
        "\n",
        "#         print(predicted_functions == actual_functions)\n",
        "#         print(predicted_function_args == actual_function_args)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['functions.create_event']\nTrue\nTrue\n"
        }
      ],
      "execution_count": 94,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735574469935
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import time\n",
        "import base64\n",
        "from typing import Any, Dict, List, Generator\n",
        "import ast"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735573134435
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install rouge-score"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: rouge-score in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.1.2)\r\nRequirement already satisfied: absl-py in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rouge-score) (2.1.0)\r\nRequirement already satisfied: nltk in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rouge-score) (3.9.1)\r\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rouge-score) (1.26.4)\r\nRequirement already satisfied: six>=1.14.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rouge-score) (1.16.0)\r\nRequirement already satisfied: click in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk->rouge-score) (8.1.7)\r\nRequirement already satisfied: joblib in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk->rouge-score) (1.4.2)\r\nRequirement already satisfied: regex>=2021.8.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk->rouge-score) (2024.7.24)\r\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk->rouge-score) (4.66.4)\r\n"
        }
      ],
      "execution_count": 96,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from rouge_score import rouge_scorer  \n",
        "\n",
        "# # Reference and candidate summaries  \n",
        "# reference = \"The cat sat on the mat.\"  \n",
        "# candidate = \"The cat is sitting on the mat.\"  \n",
        "\n",
        "# # Initialize the ROUGE scorer  \n",
        "# scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)  \n",
        "\n",
        "# # Calculate ROUGE scores  \n",
        "# scores = scorer.score(reference, candidate)  \n",
        "\n",
        "# # Print the scores  \n",
        "# print(\"ROUGE-1:\", scores['rouge1'].fmesaure)  \n",
        "# print(\"ROUGE-2:\", scores['rouge2'].fmeasure)  \n",
        "# print(\"ROUGE-L:\", scores['rougeL'].fmeasure)  "
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Score' object has no attribute 'fmesaure'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[98], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m scores \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39mscore(reference, candidate)  \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Print the scores  \u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE-1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrouge1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmesaure\u001b[49m)  \n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE-2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrouge2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfmeasure)  \n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE-L:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrougeL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfmeasure)  \n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Score' object has no attribute 'fmesaure'"
          ]
        }
      ],
      "execution_count": 98,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735575409893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(input_data : List, expected_output):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a model in selecting the correct function based on given prompts.\n",
        "\n",
        "    Args:\n",
        "        model (str): The name of the model to be evaluated.\n",
        "        system_prompt (str): The system prompt to be used in the chat completion.\n",
        "        function_list (list): A list of functions that the model can call.\n",
        "        prompts_to_expected_tool_name (dict): A dictionary mapping prompts to their expected function names.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Initialize the ROUGE Scorer where llm response is not function-call\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True) \n",
        "\n",
        "    # For generic model response without function-call, set a threshold to classify it as a match\n",
        "    match_threshold_g = 0.75\n",
        "\n",
        "    function_call_match = []\n",
        "    function_call_args_match = []\n",
        "    rouge_fmeasure_score = []\n",
        "    result_list = []\n",
        "    latencies = []\n",
        "\n",
        "    for prompt, answer in zip(input_data, expected_output):\n",
        "\n",
        "        start_time = time.time()\n",
        "        predicted_response = get_chat_completion(prompt)\n",
        "        end_time = time.time()\n",
        "\n",
        "        actual_response = answer[0]\n",
        "\n",
        "        latency = (end_time - start_time) * 1000  # convert to milliseconds\n",
        "        latencies.append(latency)\n",
        "\n",
        "        if predicted_response[1:12] == \"'tool_uses'\":\n",
        "            predicted_response = ast.literal_eval(predicted_response)\n",
        "            if isinstance(predicted_response, dict):\n",
        "                predicted_functions = [func[\"recipient_name\"] for func in predicted_response[\"tool_uses\"]]\n",
        "                predicted_function_args = [func[\"parameters\"] for func in predicted_response[\"tool_uses\"]]\n",
        "\n",
        "                actual_functions = [func[\"recipient_name\"] for func in actual_response[\"tool_uses\"]]\n",
        "                actual_function_args = [func[\"parameters\"] for func in actual_response[\"tool_uses\"]]\n",
        "\n",
        "                fcall_match = predicted_functions == actual_functions\n",
        "                fcall_args_match = predicted_function_args == actual_function_args\n",
        "                function_call_match.append(fcall_match)\n",
        "                function_call_args_match.append(fcall_args_match)\n",
        "                match = \"Yes\" if fcall_match and fcall_args_match else \"No\"\n",
        "        else:\n",
        "            fmeasure_score = scorer.score(actual_response, predicted_response)['rougeL'].fmeasure \n",
        "            rouge_fmeasure_score.append(fmeasure_score)\n",
        "            match = \"Yes\" if fmeasure_score >= match_threshold_g else \"No\"\n",
        "        \n",
        "        result_list.append(\n",
        "            {\n",
        "                \"Prompt\": prompt,\n",
        "                \"Actual\": actual_response,\n",
        "                \"Expected\": predicted_response,\n",
        "                \"Match\": match,\n",
        "            })\n",
        "\n",
        "\n",
        "    # Calculate the number of matches\n",
        "    fcall_matches = sum(function_call_match)\n",
        "    fcall_match_percentage = (fcall_matches / len(function_call_match)) * 100\n",
        "\n",
        "    # Calculate the number of correct arguments\n",
        "    fcall_args_matches = sum(function_call_args_match)\n",
        "    fcall_args_match_percentage = (fcall_args_matches/ len(function_call_args_match)) * 100\n",
        "\n",
        "    # Calculate the rouge-f1 score for non-function-call response\n",
        "    rouge_score_accuracy = sum(rouge_fmeasure_score)/len(rouge_fmeasure_score) * 100\n",
        "\n",
        "    # Calculate average latency\n",
        "    avg_latency = sum(latencies) / len(input_data)\n",
        "\n",
        "    # Create a DataFrame to store the results\n",
        "    results_df = pd.DataFrame(columns=[\"Prompt\", \"Expected\", \"Match\"])\n",
        "    results_df = pd.DataFrame(result_list)\n",
        "\n",
        "    def style_rows(row):\n",
        "        match = row[\"Match\"]\n",
        "        background_color = \"red\" if match == \"No\" else \"white\"\n",
        "        return [\"background-color: {}; color: black\".format(background_color)] * len(\n",
        "            row\n",
        "        )\n",
        "\n",
        "    styled_results_df = results_df.style.apply(style_rows, axis=1)\n",
        "\n",
        "    # Display the DataFrame as a table\n",
        "    display(styled_results_df)\n",
        "\n",
        "    print(\n",
        "        f\"Number of fcall matches: {fcall_matches} out of {len(function_call_match)} ({fcall_match_percentage:.2f}%)\"\n",
        "    )\n",
        "    print(\n",
        "        f\"Number of fcall args matches: {fcall_args_matches} out of {len(function_call_args_match)} ({fcall_args_match_percentage:.2f}%)\"\n",
        "    )\n",
        "    print(f\"Generic LLM accuracy : {rouge_score_accuracy:.2f}%\")\n",
        "    print(f\"Average latency per request: {avg_latency:.2f} ms\")"
      ],
      "outputs": [],
      "execution_count": 133,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735577483259
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = first_level_prompts[:2]\n",
        "answers = first_level_responses[:2]\n",
        "\n",
        "eval(input_data, answers)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<pandas.io.formats.style.Styler at 0x7f4f71b286a0>",
            "text/html": "<style type=\"text/css\">\n#T_780da_row0_col0, #T_780da_row0_col1, #T_780da_row0_col2, #T_780da_row0_col3, #T_780da_row1_col0, #T_780da_row1_col1, #T_780da_row1_col2, #T_780da_row1_col3 {\n  background-color: red;\n  color: black;\n}\n</style>\n<table id=\"T_780da\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_780da_level0_col0\" class=\"col_heading level0 col0\" >Prompt</th>\n      <th id=\"T_780da_level0_col1\" class=\"col_heading level0 col1\" >Actual</th>\n      <th id=\"T_780da_level0_col2\" class=\"col_heading level0 col2\" >Expected</th>\n      <th id=\"T_780da_level0_col3\" class=\"col_heading level0 col3\" >Match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_780da_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_780da_row0_col0\" class=\"data row0 col0\" >[{'role': 'system', 'content': 'You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"search_books\",\\n    \"description\": \"Search for books based on title or author\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"query\": {\\n                \"type\": \"string\",\\n                \"description\": \"The search query\"\\n            },\\n            \"author\": {\\n                \"type\": \"string\",\\n                \"description\": \"The author of the book\"\\n            }\\n        }\\n    }\\n}\\n\\n{\\n    \"name\": \"calculate_tip\",\\n    \"description\": \"Calculate the tip amount for a bill\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"bill_amount\": {\\n                \"type\": \"number\",\\n                \"description\": \"The total bill amount\"\\n            },\\n            \"tip_percentage\": {\\n                \"type\": \"number\",\\n                \"description\": \"The percentage of tip to be added\"\\n            }\\n        },\\n        \"required\": [\\n            \"bill_amount\",\\n            \"tip_percentage\"\\n        ]\\n    }\\n}'}, {'role': 'user', 'content': \"I am looking for a book but I can't remember the title. The author's name is George Orwell.\"}]</td>\n      <td id=\"T_780da_row0_col1\" class=\"data row0 col1\" >{'tool_uses': [{'recipient_name': 'functions.search_books', 'parameters': {'query': '', 'author': 'George Orwell'}}]}</td>\n      <td id=\"T_780da_row0_col2\" class=\"data row0 col2\" >{'tool_uses': [{'recipient_name': 'functions.search_books', 'parameters': {'query': 'George Orwell', 'author': 'George Orwell'}}]}</td>\n      <td id=\"T_780da_row0_col3\" class=\"data row0 col3\" >No</td>\n    </tr>\n    <tr>\n      <th id=\"T_780da_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_780da_row1_col0\" class=\"data row1 col0\" >[{'role': 'system', 'content': 'You are a helpful assistant, with no access to external functions.'}, {'role': 'user', 'content': 'Using data from the Bureau of Labor Statistics and LinkedIn, create a table of job titles for software developers in the United States, including both entry-level and senior positions, with a minimum of five possible job titles for each level. Additionally, incorporate information on the most in-demand programming languages and technologies for each job title, as well as the average salary range and required education and experience. Finally, provide a comparison of the job titles and requirements for software developer positions in the United States versus those in other countries, such as India, China, and Germany.'}]</td>\n      <td id=\"T_780da_row1_col1\" class=\"data row1 col1\" >Sure, here's a table of job titles for software developers in the United States:\n| Job Title | Programming Languages/Technologies | Average Salary Range | Education/Experience |\n| --- | --- | --- | --- |\n| Entry-Level Software Developer | Java, Python, JavaScript, SQL | $50,000 - $70,000 | Bachelor's degree in Computer Science or related field |\n| Junior Software Engineer | C++, Ruby, PHP, HTML/CSS | $60,000 - $80,000 | Bachelor's degree in Computer Science or related field with 1-2 years of experience |\n| Front-End Developer | React, Angular, Vue, HTML/CSS, JavaScript | $70,000 - $90,000 | Bachelor's degree in Computer Science or related field with 2-3 years of experience |\n| Back-End Developer | Node.js, Python, Ruby on Rails, SQL | $80,000 - $100,000 | Bachelor's degree in Computer Science or related field with 3-5 years of experience |\n| Full-Stack Developer | Java, JavaScript, Ruby on Rails, Angular, React | $90,000 - $120,000 | Bachelor's degree in Computer Science or related field with 5+ years of experience |\nIn terms of the most in-demand programming languages and technologies, it varies by job title, but some of the most commonly requested skills include Java, Python, JavaScript, Ruby on Rails, React, and Angular.\nWhen it comes to comparing software developer positions in the United States versus other countries, there are some differences in job titles and requirements. For example, in India, software developers may be referred to as software engineers, and the education and experience requirements may be different. In China, there may be more emphasis on specific technologies like WeChat and Alibaba, and in Germany, there may be a greater emphasis on open-source technologies and collaboration. However, the core skills and knowledge required for software development are generally similar across countries.</td>\n      <td id=\"T_780da_row1_col2\" class=\"data row1 col2\" >Based on data from the Bureau of Labor Statistics and LinkedIn, here is a table of job titles for software developers in the United States, including both entry-level and senior positions, with a minimum of five possible job titles for each level:\n| Job Title | Entry-Level | Senior |\n| --- | --- | --- |\n| Software Developer | Junior Software Developer, Software Engineer, Junior Developer, Software Developer Intern, Entry-Level Software Developer | Senior Software Developer, Lead Software Developer, Software Architect, Technical Lead, Senior Software Engineer |\n| Average Salary Range | $60,000 - $80,000 | $100,000 - $150,000 |\n| Required Education and Experience | Bachelor's degree in Computer Science or related field, 0-2 years of experience | Bachelor's degree in Computer Science or related field, 2-5 years of experience |\n| Most In-Demand Programming Languages and Technologies | Java, Python, JavaScript, C++, SQL, Agile methodologies |\n| Job Title | Entry-Level | Senior |\n| Software Developer | Junior Software Developer, Software Engineer, Junior Developer, Software Developer Intern, Entry-Level Software Developer | Senior Software Developer, Lead Software Developer, Software Architect, Technical Lead, Senior Software Engineer |\n| Average Salary Range | $60,000 - $80,000 | $100,000 - $150,000 |\n| Required Education and Experience | Bachelor's degree in Computer Science or related field, 0-2 years of experience | Bachelor's degree in Computer Science or related field, 2-5 years of experience |\n| Most In-Demand Programming Languages and Technologies | Java, Python, JavaScript, C++, SQL, Agile methodologies |\n| Job Title | Entry-Level | Senior |\n| Software Developer | Junior Software Developer, Software Engineer, Junior Developer, Software Developer Intern, Entry-Level Software Developer | Senior Software Developer, Lead Software Developer, Software Architect, Technical Lead, Senior Software Engineer |\n| Average Salary Range | $60,000 - $80,000 | $100,000 - $150,000 |\n| Required Education and Experience | Bachelor's degree in Computer Science or related field, 0-2 years of experience | Bachelor's degree in Computer Science or related field, 2-5 years of experience |\n| Most In-Demand Programming Languages and Technologies | Java, Python, JavaScript, C++, SQL, Agile methodologies |\n| Job Title | Entry-Level | Senior |\n| Software Developer | Junior Software Developer, Software Engineer, Junior Developer, Software Developer Intern, Entry-Level Software Developer | Senior Software Developer, Lead Software Developer, Software Architect, Technical Lead, Senior Software Engineer |\n| Average Salary Range | $60,000 - $80,000 | $100,000 - $150,000 |\n| Required Education and Experience | Bachelor's degree in Computer Science or related field, 0-2 years of experience | Bachelor's degree in Computer Science or related field, 2-5 years of experience |\n| Most In-Demand Programming Languages and Technologies | Java, Python, JavaScript, C++, SQL, Agile methodologies |\n| Job Title | Entry-Level | Senior |\n| Software Developer | Junior Software Developer, Software Engineer, Junior Developer, Software Developer Intern, Entry-Level Software Developer | Senior Software Developer, Lead Software Developer, Software Architect, Technical Lead, Senior Software Engineer |\n| Average Salary Range | $60,000 - $80,000 | $100,000 - $150,000 |\n| Required Education and Experience | Bachelor's degree in Computer Science or related field, 0-2 years of experience | Bachelor's degree in Computer Science or related field, 2-5 years of experience |\n| Most In-Demand Programming Languages and Technologies | Java, Python, JavaScript, C++, SQL, Agile methodologies |\n| Job Title | Entry-Level | Senior |\n| Software Developer | Junior Software Developer, Software Engineer, Junior Developer, Software Developer Intern, Entry-Level Software Developer | Senior Software Developer, Lead Software Developer, Software Architect, Technical Lead, Senior Software Engineer |\n| Average Salary Range | $60,000 - $80,000 | $100,000 - $150,000 |\n| Required Education and Experience | Bachelor's degree in Computer Science or related field, 0-2 years of experience | Bachelor's degree in Computer Science or related field, 2-5 years of experience |\n| Most In-Demand Programming Languages and Technologies | Java, Python, JavaScript, C++, SQL, Agile methodologies |\n| Job Title | Entry-Level | Senior |\n| Software Developer | Junior Software Developer, Software Engineer, Junior Developer, Software Developer Intern, Entry-Level Software Developer | Senior Software Developer, Lead Software Developer, Software Architect, Technical Lead, Senior Software Engineer |\n| Average Salary Range | $60,000 - $80,000 | $100,000 - $150,000 |\n| Required Education and Experience | Bachelor's degree in Computer Science or related field, 0-2 years of experience | Bachelor's degree in Computer Science or related field, 2-5 years of experience |\n| Most In-Demand Programming Languages and Technologies | Java, Python</td>\n      <td id=\"T_780da_row1_col3\" class=\"data row1 col3\" >No</td>\n    </tr>\n  </tbody>\n</table>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of fcall matches: 1 out of 1 (100.00%)\nNumber of fcall args matches: False out of 1 (0.00%)\nGeneric LLM accuracy : 27.38%\nAverage latency per request: 11471.86 ms\n"
        }
      ],
      "execution_count": 132,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1735577398494
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "version_major": 2,
        "version_minor": 0,
        "state": {
          "a0595c495edf4a41a2c880905fb398f0": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "1e6e77a9b4c447d6b7081e91531273f2": {
            "model_name": "ProgressStyleModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "ProgressStyleModel",
              "_model_module": "@jupyter-widgets/controls",
              "description_width": "",
              "_view_name": "StyleView",
              "_view_module": "@jupyter-widgets/base",
              "_view_count": null,
              "bar_color": null,
              "_model_module_version": "2.0.0"
            }
          },
          "6f54e7c6759d42fda30e87071f7e9301": {
            "model_name": "FloatProgressModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "FloatProgressModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "max": 2,
              "description_allow_html": false,
              "bar_style": "",
              "_view_name": "ProgressView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_e5fdc97f08d746bb913b7ab21ee479dc",
              "orientation": "horizontal",
              "value": 0,
              "style": "IPY_MODEL_1e6e77a9b4c447d6b7081e91531273f2",
              "min": 0,
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "description": ""
            }
          },
          "f61b9723ddc54c2ca69b0c5e052804ce": {
            "model_name": "HBoxModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HBoxModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "_view_name": "HBoxView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_c4a9a3ba9b624f1591a12cdf62d34897",
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "box_style": "",
              "children": [
                "IPY_MODEL_a7d87a8fc10343ed8bd6259bac568d5b",
                "IPY_MODEL_6f54e7c6759d42fda30e87071f7e9301",
                "IPY_MODEL_93eaf6da605a4cef8781cb0bfbc50b8d"
              ]
            }
          },
          "8c82774c295c4004ba1d8607f4a835ee": {
            "model_name": "HBoxModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HBoxModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "_view_name": "HBoxView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_81da9e28114d4c1cb067e6bc0aa9aaf3",
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "box_style": "",
              "children": [
                "IPY_MODEL_ce1f401893db48eb9d0acc0679d7d02e",
                "IPY_MODEL_a3b47eede0b64c38919c5cf585cae695",
                "IPY_MODEL_0995017e759f49cda9da73d104e94b0e"
              ]
            }
          },
          "ce1f401893db48eb9d0acc0679d7d02e": {
            "model_name": "HTMLModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "description_allow_html": false,
              "_view_name": "HTMLView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_8c6c22a589684f7e9948e15893045f5b",
              "value": "Loading checkpoint shards:   0%",
              "style": "IPY_MODEL_3f6a4e30439e4d7b9920071bfb0c2d68",
              "placeholder": "​",
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "disabled": false,
              "description": ""
            }
          },
          "ac19ee74ede44453a6a2518e7149b5b9": {
            "model_name": "ProgressStyleModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "ProgressStyleModel",
              "_model_module": "@jupyter-widgets/controls",
              "description_width": "",
              "_view_name": "StyleView",
              "_view_module": "@jupyter-widgets/base",
              "_view_count": null,
              "bar_color": null,
              "_model_module_version": "2.0.0"
            }
          },
          "3f6a4e30439e4d7b9920071bfb0c2d68": {
            "model_name": "HTMLStyleModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLStyleModel",
              "_model_module": "@jupyter-widgets/controls",
              "description_width": "",
              "_view_name": "StyleView",
              "_view_module": "@jupyter-widgets/base",
              "background": null,
              "text_color": null,
              "font_size": null,
              "_view_count": null,
              "_model_module_version": "2.0.0"
            }
          },
          "a3b47eede0b64c38919c5cf585cae695": {
            "model_name": "FloatProgressModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "FloatProgressModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "max": 2,
              "description_allow_html": false,
              "bar_style": "",
              "_view_name": "ProgressView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_e036392155f64ce780d6e972d5e45863",
              "orientation": "horizontal",
              "value": 0,
              "style": "IPY_MODEL_ac19ee74ede44453a6a2518e7149b5b9",
              "min": 0,
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "description": ""
            }
          },
          "93eaf6da605a4cef8781cb0bfbc50b8d": {
            "model_name": "HTMLModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "description_allow_html": false,
              "_view_name": "HTMLView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_1b05d51dba1d49e1b04e61d0b9154bf3",
              "value": " 0/2 [00:00&lt;?, ?it/s]",
              "style": "IPY_MODEL_6e3f12ca0b574bf4b0ca49719b295557",
              "placeholder": "​",
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "disabled": false,
              "description": ""
            }
          },
          "6e3f12ca0b574bf4b0ca49719b295557": {
            "model_name": "HTMLStyleModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLStyleModel",
              "_model_module": "@jupyter-widgets/controls",
              "description_width": "",
              "_view_name": "StyleView",
              "_view_module": "@jupyter-widgets/base",
              "background": null,
              "text_color": null,
              "font_size": null,
              "_view_count": null,
              "_model_module_version": "2.0.0"
            }
          },
          "81da9e28114d4c1cb067e6bc0aa9aaf3": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "e5fdc97f08d746bb913b7ab21ee479dc": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "a7d87a8fc10343ed8bd6259bac568d5b": {
            "model_name": "HTMLModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "description_allow_html": false,
              "_view_name": "HTMLView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_a0595c495edf4a41a2c880905fb398f0",
              "value": "Loading checkpoint shards:   0%",
              "style": "IPY_MODEL_4e7db47970894fefa4180b512e2d5818",
              "placeholder": "​",
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "disabled": false,
              "description": ""
            }
          },
          "05f7815d362341e19d1272501c2c7b93": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "4e7db47970894fefa4180b512e2d5818": {
            "model_name": "HTMLStyleModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLStyleModel",
              "_model_module": "@jupyter-widgets/controls",
              "description_width": "",
              "_view_name": "StyleView",
              "_view_module": "@jupyter-widgets/base",
              "background": null,
              "text_color": null,
              "font_size": null,
              "_view_count": null,
              "_model_module_version": "2.0.0"
            }
          },
          "88b4b30e873a4bae8a2bdf422f44f008": {
            "model_name": "HTMLStyleModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLStyleModel",
              "_model_module": "@jupyter-widgets/controls",
              "description_width": "",
              "_view_name": "StyleView",
              "_view_module": "@jupyter-widgets/base",
              "background": null,
              "text_color": null,
              "font_size": null,
              "_view_count": null,
              "_model_module_version": "2.0.0"
            }
          },
          "1b05d51dba1d49e1b04e61d0b9154bf3": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "c4a9a3ba9b624f1591a12cdf62d34897": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "e036392155f64ce780d6e972d5e45863": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "8c6c22a589684f7e9948e15893045f5b": {
            "model_name": "LayoutModel",
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "grid_row": null,
              "_model_module": "@jupyter-widgets/base",
              "overflow": null,
              "max_height": null,
              "display": null,
              "border_top": null,
              "grid_auto_flow": null,
              "grid_template_rows": null,
              "align_self": null,
              "grid_auto_columns": null,
              "width": null,
              "grid_area": null,
              "align_items": null,
              "_view_name": "LayoutView",
              "left": null,
              "height": null,
              "_view_module": "@jupyter-widgets/base",
              "border_right": null,
              "object_position": null,
              "justify_content": null,
              "bottom": null,
              "max_width": null,
              "margin": null,
              "order": null,
              "grid_column": null,
              "grid_auto_rows": null,
              "padding": null,
              "grid_template_columns": null,
              "justify_items": null,
              "object_fit": null,
              "visibility": null,
              "_view_count": null,
              "flex_flow": null,
              "min_height": null,
              "top": null,
              "min_width": null,
              "flex": null,
              "border_left": null,
              "_model_module_version": "2.0.0",
              "grid_template_areas": null,
              "right": null,
              "grid_gap": null,
              "border_bottom": null,
              "align_content": null
            }
          },
          "0995017e759f49cda9da73d104e94b0e": {
            "model_name": "HTMLModel",
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "state": {
              "_view_module_version": "2.0.0",
              "_model_name": "HTMLModel",
              "_model_module": "@jupyter-widgets/controls",
              "tooltip": null,
              "description_allow_html": false,
              "_view_name": "HTMLView",
              "tabbable": null,
              "_view_module": "@jupyter-widgets/controls",
              "_dom_classes": [],
              "layout": "IPY_MODEL_05f7815d362341e19d1272501c2c7b93",
              "value": " 0/2 [00:00&lt;?, ?it/s]",
              "style": "IPY_MODEL_88b4b30e873a4bae8a2bdf422f44f008",
              "placeholder": "​",
              "_view_count": null,
              "_model_module_version": "2.0.0",
              "disabled": false,
              "description": ""
            }
          }
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}