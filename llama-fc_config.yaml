config:
    AZURE_SUBSCRIPTION_ID: "" # Please modify to your subscription
    AZURE_RESOURCE_GROUP: "" # Please modify to your Azure resource group
    AZURE_WORKSPACE: "" # Please modify to your Azure workspace
    AZURE_SFT_DATA_NAME: "sft-demo-data-function-call" # Please modify to your AzureML data name
    SFT_DATA_DIR: "./dataset"
    CLOUD_DIR: "./cloud"
    HF_MODEL_NAME_OR_PATH: "unsloth/Llama-3.2-3B-Instruct"
    HF_TOKEN: "" # Please modify to your Hugging Face token
    IS_DEBUG: true
    USE_LOWPRIORITY_VM: false

train:
    azure_env_name: "v" # Please modify to your AzureML env name
    azure_compute_cluster_name: "gpu-a100-demo-vm"
    azure_compute_cluster_size: "Standard_NC24ads_A100_v4" # 1 x A100 (80GB)
    epoch: 1
    train_batch_size: 10
    eval_batch_size: 10
    model_dir: "./outputs"
    wandb_api_key: "" # Please modify to your W&B API key if you want to use W&B
    wandb_project: "azureml-finetune"
    wandb_watch: "gradients"

serve:
    azure_env_name: "slm-serving-llama" # Please modify to your AzureML env name
    azure_model_name: "llama-fc-ft" # Please modify to your AzureML model name
    azure_endpoint_name: "llama-endpoint-ft"
    azure_deployment_name: "llama-fc-ft"
    azure_compute_cluster_name: "gpu-a100-demo-vm"
    azure_serving_cluster_size: "Standard_NC24ads_A100_v4"
